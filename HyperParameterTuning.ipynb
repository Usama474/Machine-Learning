{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "096f53ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "d= load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ba3f75b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.DataFrame(d.data, columns= d.feature_names)\n",
    "df['target']= d.target\n",
    "df\n",
    "Y= df.target\n",
    "X= df.drop(['target'], axis= 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bacd3044",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getscore(model, xtrn,xtst, ytrn, ytst):\n",
    "    model.fit(xtrn, ytrn)\n",
    "    return model.score(xtst, ytst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e44f2c8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python3.10\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Random Forest': 0.9220055710306406,\n",
       " 'Decision Tree': 0.7910863509749304,\n",
       " 'SVM': 0.9415041782729805,\n",
       " 'Logistic Regression': 0.8997214484679665,\n",
       " 'Gaussian Baive Bayes': 0.8133704735376045}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "score={}\n",
    "models={'Random Forest':RandomForestClassifier(),'Decision Tree': DecisionTreeClassifier(),'SVM': SVC(),\n",
    "        'Logistic Regression': LogisticRegression(solver='lbfgs',max_iter=2500), 'Gaussian Baive Bayes' : GaussianNB()}\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "kf= KFold(n_splits=5)\n",
    "for a, b in models.items():\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        xtrain,xtest,ytrain,ytest = d.data[train_index], d.data[test_index], Y[train_index], Y[test_index]\n",
    "        score.update( {a :getscore(models[a],xtrain, xtest, ytrain, ytest)})\n",
    "      \n",
    "\n",
    "\n",
    "score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "314483db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python3.10\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Random Forest': array([0.91944444, 0.91111111, 0.96100279, 0.9637883 , 0.91643454]),\n",
       " 'Decision Tree': array([0.78611111, 0.70277778, 0.79108635, 0.83286908, 0.80501393]),\n",
       " 'SVM': array([0.96111111, 0.94444444, 0.98328691, 0.98885794, 0.93871866]),\n",
       " 'Logistic Regression': array([0.925     , 0.87777778, 0.93871866, 0.93593315, 0.89693593]),\n",
       " 'Gaussian Baive Bayes': array([0.78055556, 0.78333333, 0.79387187, 0.8718663 , 0.80501393])}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict={}\n",
    "for a, b in models.items():\n",
    "    dict[a] = cross_val_score(models[a], X, Y, cv= 5)\n",
    "\n",
    "dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "721d21cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'linear_10': 0.9476973073351903,\n",
       " 'linear_20': 0.9476973073351903,\n",
       " 'linear_30': 0.9476973073351903,\n",
       " 'poly_10': 0.96884246363355,\n",
       " 'poly_20': 0.96884246363355,\n",
       " 'poly_30': 0.96884246363355,\n",
       " 'rbf_10': 0.9738502011761063,\n",
       " 'rbf_20': 0.9738502011761063,\n",
       " 'rbf_30': 0.9738502011761063}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now Having leanrt That that cross_val_score does exactly the same thing Now its time for Parameter Tuning\n",
    "\n",
    "performance={}\n",
    "SVM= []\n",
    "Rand= []\n",
    "decision=[]\n",
    "c=[10, 20, 30]\n",
    "k= ['linear', 'poly', 'rbf']\n",
    "for a in k:\n",
    "    for b in c:\n",
    "        performance[str(a)+\"_\"+str(b) ]= np.average(cross_val_score(SVC(C=b,kernel=a), X, Y, cv= 5))\n",
    "performance\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "173abdad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.0393271 , 0.04374347, 0.07355628, 0.04686351, 0.05086412,\n",
       "        0.08181486, 0.04374347, 0.06574044, 0.10213704]),\n",
       " 'std_fit_time': array([0.01030633, 0.00624959, 0.00619107, 0.00986894, 0.00729119,\n",
       "        0.01452679, 0.00625032, 0.01816208, 0.02042442]),\n",
       " 'mean_score_time': array([0.01558447, 0.01562777, 0.04875002, 0.01127901, 0.0156981 ,\n",
       "        0.05446367, 0.01563134, 0.01196575, 0.04701605]),\n",
       " 'std_score_time': array([8.65541538e-05, 1.05120696e-06, 1.63773016e-02, 6.11687331e-03,\n",
       "        1.42276702e-04, 1.60345110e-02, 5.79823004e-06, 1.16064945e-02,\n",
       "        1.61084446e-02]),\n",
       " 'param_C': masked_array(data=[10, 10, 10, 20, 20, 20, 30, 30, 30],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_kernel': masked_array(data=['linear', 'poly', 'rbf', 'linear', 'poly', 'rbf',\n",
       "                    'linear', 'poly', 'rbf'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'C': 10, 'kernel': 'linear'},\n",
       "  {'C': 10, 'kernel': 'poly'},\n",
       "  {'C': 10, 'kernel': 'rbf'},\n",
       "  {'C': 20, 'kernel': 'linear'},\n",
       "  {'C': 20, 'kernel': 'poly'},\n",
       "  {'C': 20, 'kernel': 'rbf'},\n",
       "  {'C': 30, 'kernel': 'linear'},\n",
       "  {'C': 30, 'kernel': 'poly'},\n",
       "  {'C': 30, 'kernel': 'rbf'}],\n",
       " 'split0_test_score': array([0.96388889, 0.98333333, 0.98055556, 0.96388889, 0.98333333,\n",
       "        0.98055556, 0.96388889, 0.98333333, 0.98055556]),\n",
       " 'split1_test_score': array([0.91944444, 0.94444444, 0.95833333, 0.91944444, 0.94444444,\n",
       "        0.95833333, 0.91944444, 0.94444444, 0.95833333]),\n",
       " 'split2_test_score': array([0.96657382, 0.98050139, 0.98328691, 0.96657382, 0.98050139,\n",
       "        0.98328691, 0.96657382, 0.98050139, 0.98328691]),\n",
       " 'split3_test_score': array([0.9637883 , 0.98885794, 0.98885794, 0.9637883 , 0.98885794,\n",
       "        0.98885794, 0.9637883 , 0.98885794, 0.98885794]),\n",
       " 'split4_test_score': array([0.92479109, 0.94707521, 0.95821727, 0.92479109, 0.94707521,\n",
       "        0.95821727, 0.92479109, 0.94707521, 0.95821727]),\n",
       " 'mean_test_score': array([0.94769731, 0.96884246, 0.9738502 , 0.94769731, 0.96884246,\n",
       "        0.9738502 , 0.94769731, 0.96884246, 0.9738502 ]),\n",
       " 'std_test_score': array([0.02097775, 0.01905577, 0.01299544, 0.02097775, 0.01905577,\n",
       "        0.01299544, 0.02097775, 0.01905577, 0.01299544]),\n",
       " 'rank_test_score': array([7, 4, 1, 7, 4, 1, 7, 4, 1])}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now what if we have to chose for many folds of dataset, then for different parameters of a classifier\n",
    "#and then in between different  classfiers is not it confusing?? YES, but dont worry. We have Grid Seach\n",
    "# or grid search cross validation\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid= GridSearchCV(SVC(), {'C': [10, 20, 30], 'kernel': ['linear', 'poly', 'rbf']}, cv=5)\n",
    "                   \n",
    "grid.fit(X, Y)\n",
    "grid.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2153795c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_kernel</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.947697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.968842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.973850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.947697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.968842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.973850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>30</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.947697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>30</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.968842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>30</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.973850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_C param_kernel  mean_test_score\n",
       "0      10       linear         0.947697\n",
       "1      10         poly         0.968842\n",
       "2      10          rbf         0.973850\n",
       "3      20       linear         0.947697\n",
       "4      20         poly         0.968842\n",
       "5      20          rbf         0.973850\n",
       "6      30       linear         0.947697\n",
       "7      30         poly         0.968842\n",
       "8      30          rbf         0.973850"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2= pd.DataFrame(grid.cv_results_)\n",
    "df2[['param_C', 'param_kernel', 'mean_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b76bdf30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9738502011761063"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "49bed4af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "69e5fc59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier()\n",
      "DecisionTreeClassifier()\n",
      "SVC()\n",
      "LogisticRegression(max_iter=2500)\n",
      "GaussianNB()\n"
     ]
    }
   ],
   "source": [
    "for x,y in models.items():\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "caaceff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model= { \n",
    "    'svm':{ 'model': SVC(),\n",
    "            'params': {'C': [10, 20, 30], 'kernel':['poly', 'rbf'] }},\n",
    "    'Random Forest': { 'model': RandomForestClassifier(),\n",
    "                       'params': {'n_estimators':[20, 30, 50], 'criterion':[\"gini\", \"entropy\"] }},\n",
    "    'Decision Tree' : { 'model': DecisionTreeClassifier(), \n",
    "                        'params': {'criterion':[\"gini\", \"entropy\"],'splitter' :[\"best\", \"random\"]}},\n",
    "'Logistic Regression': {'model' :LogisticRegression(max_iter=1000), \n",
    "                        'params': {'penalty' : ['l1', 'l2', 'elasticnet', 'none'], \n",
    "                                   'solver' : ['newton-cg', 'lbfgs', 'liblinear'] }}\n",
    "    \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "022a2cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python3.10\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Python3.10\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Python3.10\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Python3.10\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "18 fits failed out of a total of 36.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Python3.10\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Python3.10\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Python3.10\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Python3.10\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Python3.10\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Python3.10\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Python3.10\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Python3.10\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Python3.10\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Python3.10\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Python3.10\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Python3.10\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Python3.10\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Python3.10\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Python3.10\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 457, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Python3.10\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Python3.10\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Python3.10\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 464, in _check_solver\n",
      "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Python3.10\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.91930996 0.92877017 0.92877017 0.91930996\n",
      "        nan        nan        nan 0.92097941 0.9081803         nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'Model': 'svm',\n",
       "  'Best Scores': 0.9738452977184195,\n",
       "  'Best parameter': {'C': 10, 'kernel': 'rbf'}},\n",
       " {'Model': 'Random Forest',\n",
       "  'Best Scores': 0.9343350027824151,\n",
       "  'Best parameter': {'criterion': 'gini', 'n_estimators': 50}},\n",
       " {'Model': 'Decision Tree',\n",
       "  'Best Scores': 0.8063439065108513,\n",
       "  'Best parameter': {'criterion': 'entropy', 'splitter': 'random'}},\n",
       " {'Model': 'Logistic Regression',\n",
       "  'Best Scores': 0.9287701725097385,\n",
       "  'Best parameter': {'penalty': 'l2', 'solver': 'newton-cg'}}]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Scores=[]\n",
    "for key, value in Model.items():\n",
    "    grid= GridSearchCV(value['model'], value['params'], cv=3, return_train_score=False)\n",
    "    grid.fit(X,Y)\n",
    "    Scores.append({\n",
    "    'Model': key,\n",
    "    'Best Scores': grid.best_score_, \n",
    "    'Best parameter': grid.best_params_\n",
    "                   \n",
    "    })\n",
    "\n",
    "Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "5d88bda3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Best Scores</th>\n",
       "      <th>Best parameter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm</td>\n",
       "      <td>0.973845</td>\n",
       "      <td>{'C': 10, 'kernel': 'rbf'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.934335</td>\n",
       "      <td>{'criterion': 'gini', 'n_estimators': 50}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.806344</td>\n",
       "      <td>{'criterion': 'entropy', 'splitter': 'random'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.928770</td>\n",
       "      <td>{'penalty': 'l2', 'solver': 'newton-cg'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Best Scores  \\\n",
       "0                  svm     0.973845   \n",
       "1        Random Forest     0.934335   \n",
       "2        Decision Tree     0.806344   \n",
       "3  Logistic Regression     0.928770   \n",
       "\n",
       "                                   Best parameter  \n",
       "0                      {'C': 10, 'kernel': 'rbf'}  \n",
       "1       {'criterion': 'gini', 'n_estimators': 50}  \n",
       "2  {'criterion': 'entropy', 'splitter': 'random'}  \n",
       "3        {'penalty': 'l2', 'solver': 'newton-cg'}  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF= pd.DataFrame(Scores, columns=['Model', 'Best Scores', 'Best parameter'] )\n",
    "DF"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
